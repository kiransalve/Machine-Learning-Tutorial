
Tensors is basic data structure

It is so important that googles library Tensorflow named from Tensor

It is container, where we store numbers (for 99.99%)

0 dimension - Scalars (2), (3)
1 dimension - Vectors, 
2D Matrics are all tensors as general term 

tensors and n-dimensional array are same thing

1d array
2d array ke andar array
3d array ke andar array uske andar array

axis means how many dimension you have

suppose 
a = [1,2,3,4]
It is one dimension vector 
it is 1d array
it is 1d tensor

but how many dimensions it have - 4d
becasue it has 4 numbers

same 
b = [3,5,6]
It is one dimension vector 
it is 1d array
it is 1d tensor

but it have 3d dimensions

another imporatant thing 
if we add multiple scalars then we get vectors
if we add "pichhala" dimension then we get next dimension

No. of Rank = No. of Axes = No. of Dimension

Shape means "row me aap maximum kitane item store kar sakte ho aur column me aap maximum kitane item store kar sakte ho"

shape (2,3)

Size is row X cols
it is total item in tensor

1. 1D Tesnsor
suppose we have table with iq, cgpa, place and placement for 10,000 students
so suppose first student have these value like 

iq cgpa place placement
_______________________
91  8.1  WB    Yes
_______________________

so we can write input columns - [91, 8.1, 0]

we taken 0 for WB value

if another student

iq cgpa place placement
_______________________
60  4.1  MH    No
_______________________

input columns - [60, 4.1, 1]

we take MH as 1 (called label encoding)

so these input columns are 1d tensors
and has 3 dimension

so we have 10,000 vectors with 1d tensors with each vector has 3 dimensions

2. 2D tesnors

if we take collection of 10,000 vectors and store them in matrix then it is 2d tensors
and placement is 1d tensor with 10,000 dimensions

3. 3D tensor

we find 3d tensor in NLP 

Example 1

Hi kiran
Hi ram
Hi krishna

vectorization ->
Hi kiran ram krishna
1   0     0    0
0   1     0    0
0   0     1    0
0   0     0    1

Hi kiran - [[1,0,0,0],[0,1,0,0]]
Hi ram - [[1,0,0,0],[0,0,1,0]]
Hi krishna - [[1,0,0,0],[0,0,0,1]]

[ [[1,0,0,0],[0,1,0,0]],
 [[1,0,0,0],[0,0,1,0]],
 [[1,0,0,0],[0,0,0,1]] ]

shape - (3, 2, 4)

Example 2
Timeseries data
We track high and low of stock for daily for one year

Highest | Lowest
245        244
245        243
246        243

this is 2d tensor

and we have 10 years of data now
now we have 10 2d tensors
so we have 3d tensors 
shape (10, 365, 2)


4. 4D Tensor 

In computer vision and deep learning, the most common 4D tensor format is
(batch_size, channels, height, width)

Each dimension means:

Batch size – number of images processed at once.
Channels – 3 for RGB, 1 for grayscale.
Height – image height in pixels.
Width – image width in pixels.

Example

Let’s say you have:
A batch of 10 RGB images
Each image is of size 64x64
Then the 4D tensor shape will be:

(10, 3, 64, 64)

10 → number of images (batch size)
3 → RGB channels
64 → height
64 → width

5. 5d tensors

A 5D tensor is a five-dimensional data structure. 

4D tensor is like a collection of images, which
crossed from our eyes with more than 12 images per seconds,
our eyes interprete it as video 

In deep learning (especially video processing or volumetric data), the shape of a 5D tensor is usually:

(batch_size, channels, depth, height, width)

Where:
batch_size: number of video clips or samples
channels: like RGB (3 channels) or grayscale (1 channel)
depth: number of frames in a video (or slices in 3D scan)
height: image height
width: image width

Example: Video Data

Let’s say you have:
8 videos (batch_size)
Each video is 10 frames long (depth)
RGB (3 channels)
Each frame is 64x64 pixels
Then the tensor shape would be:

(8, 3, 10, 64, 64)

tensor[0] → First video
tensor[0, 1] → Green channel of first video
tensor[0, 1, 5] → 6th frame of green channel of first video
tensor[0, 1, 5, 20, 30] → Pixel at row 20, column 30 in 6th frame of green channel of first video
