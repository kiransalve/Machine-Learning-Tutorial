#  How to find m and b?

![lr](https://github.com/user-attachments/assets/67a54634-25c7-447c-a861-d7739ea3aea8)

| Symbol | Meaning                            | Example             |
| ------ | ---------------------------------- | ------------------- |
| `y`    | Output / Dependent variable        | Package ðŸ’°          |
| `x`    | Input / Independent variable       | CGPA ðŸŽ“             |
| `m`    | Slope of the line                  | 1.5 (growth factor) |
| `b`    | Intercept (where line cuts y-axis) | 2.0 (base salary)   |


we can solve above equetion by two method

1. Closed form solution

direct formula

also called Ordinary least square

2. Non - closed form solution

approximation based technique

where we use differentiation

called Gradient Descent

Why there is Gradient Descent if we have direct formula?

because in higher dimmension, (more feature or columns) to perform calculation become complex and takes more energy

but in scikit class there are OLS is implemented

we have SGDRegressor() that uses GD

#

# Invent the formula from Scratch

![lr1](https://github.com/user-attachments/assets/4a8db174-7c50-4ed1-8651-9778a1fdd697)

![lr2](https://github.com/user-attachments/assets/fa216526-d92e-4acd-85f4-22a015c6cd0f)

Suppose we have cgpa vs package data

![lr3](https://github.com/user-attachments/assets/93c27000-68d2-46a0-9d86-57db4a98a658)

if we have perfect linear data then we drow a line that go throgh each of the data points.

but in our case or in real word our data always or 99.99% sort of linear.

we cant drow perfect linear line but we can drow best fit line, that tries to go cover each data point very closely.

and this will do some error for each like

har data point ke liye hamara line thoda galati karega, kabhi data ke uper jayega kabhi niche

that will be the error for each data point

also it is the distance between actual and predicted value

and can be denoted as d1, d2, d3, .... dn (n is last data point or no. of data points)

![l3](https://github.com/user-attachments/assets/8673c1fe-c882-4694-b562-78705adc0957)

so we want total error then we add it all

E = d1 + d2 + d3 + ... + dn

![l5](https://github.com/user-attachments/assets/86974079-6677-4645-891d-412fed82f0c9)

![l4](https://github.com/user-attachments/assets/3d49402f-2764-4937-a1bd-763b806bff9f)

It is error function (loss function)

we take square becasue we have to ensures no cancellation of positive/negative errors

why we not take mod of data points 

because 

1. We have to punish outlier
2. We have to differntiate the equetion afterwords, and graph of mod is not continuous at origin

Ok. so before we want to find out the line that passes closely by each data points, 
now our goal is to find the minimum value of above error function, 
we want value m and b such that e is minimum
jo line sabse kam galati karega vahi hamara best fit line hoga.

if we observe the d , it is nothing but it is the difference between predicted value and actual value on y axis 

![l6](https://github.com/user-attachments/assets/aeafeacc-dd50-4e97-ae3d-185dd3392327)

we want Total measure of mistakes

![l7](https://github.com/user-attachments/assets/3c59b622-a2f4-4e30-8842-5aec34895a1e)
