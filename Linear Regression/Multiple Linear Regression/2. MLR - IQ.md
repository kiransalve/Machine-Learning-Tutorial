What is Multiple Linear Regression?

Multiple Linear Regression is a method used to predict a value based on two or more inputs features.

Difference between SLR and MLR?

SLR have one indenpendant feature and MLR have two or more independant features

SLR - y = Bo + B1X1

MRL - y = Bo + B1X1 + B2X2 + B3X3 .. + BnXn

SLR - one streight line that try to go throgh all data points

MLR - plane or hyperplane that try to cut all data points

SLR - Linearity, independence, homoscedasticity, normality of residuals

MLR - Same assumptions, but also includes no multicollinearity


What assumptions does multiple linear regression make?

Linearity

The relationship between the dependent variable (Y) and the independent variables (X₁, X₂, ..., Xₙ) is linear.

Check with: Residual vs. Fitted plot — it should not show curves or patterns.

Independence of Errors

The residuals (errors) should be independent of each other.

Homoscedasticity (Constant Variance of Errors)

The variance of residuals should be constant across all levels of the independent variables.

No Multicollinearity

The independent variables should not be highly correlated with each other.

Normality of Residuals

The residuals should be normally distributed.


What is Multicollinearity and How Do You Detect It?

Multicollinearity occurs when two or more independent variables in a regression model are highly correlated with each other.

To Detect Multicollinearity Correlation Matrix

Check pairwise correlations between features

If correlation > 0.8 or < -0.8, multicollinearity may be present

To Handle Multicollinearity

Remove or combine correlated features

Use PCA (Principal Component Analysis)

Use Ridge regression (adds penalty to reduce coefficient instability)
